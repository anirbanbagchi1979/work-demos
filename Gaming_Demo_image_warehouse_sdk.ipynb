{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirbanbagchi1979/work-demos/blob/main/Gaming_Demo_image_warehouse_sdk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX2wUzd3gjTc"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Image Warehouse SDK demo\n",
        "\n",
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/vision/image_warehouse_sdk.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/vision/image_warehouse_sdk.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>                                                                                         \n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/vision/image_warehouse_sdk.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI8d5ytBhfuw"
      },
      "source": [
        "**_NOTE_**: This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENEut1m0h3Uo"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Learn how to build a [Image Warehouse](https://cloud.google.com/vision-ai/docs) step by step by using SDK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMF4pbEIuZS2"
      },
      "source": [
        "### Objective\n",
        "The objective is to demostrate how to use Image Warehouse for image data ingestion and perform similarity search given text query or image as inputs. It contains examples using critical Warehouse APIs and the pipeline to perform E2E data ingestion and search journey. The colab builds a Warehouse Corpus with thousands of images ingested, analyzed and indexed; and an Index Endpoint to perform search over the images. The CUJ is as following:\n",
        "\n",
        "* Create Corpus\n",
        "* Create Data Schema\n",
        "* Import Assets\n",
        "* Analyze Corpus\n",
        "* Create Index\n",
        "* Create Index Endpoint\n",
        "* Deploy Index\n",
        "* Perform Search\n",
        "* Cleanup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzdLmFrajntF"
      },
      "source": [
        "### Dataset\n",
        "The dataset used in this demo is publicly accessible at [gs://cloud-samples-data/ai-platform/flowers](https://pantheon.corp.google.com/storage/browser/cloud-samples-data/ai-platform/flowers). It contains 3670 images of five kinds of flowers.\n",
        "\n",
        "The metadata file are publicly accessible at [gs://cloud-samples-data/vertex-ai-vision/warehouse/demo.jsonl](https://pantheon.corp.google.com/storage/browser/_details/cloud-samples-data/vertex-ai-vision/warehouse/demo.jsonl). It contains the annotations for each image file. The colab scans the metadata file and import the images and annotations into the warehouse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQV4SMLUqchE"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "Vertex AI Vision ([Pricing](https://cloud.google.com/vision-ai/pricing))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ7438Mugipn"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the following packages required to execute this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_uWAql-Rnvv",
        "outputId": "98fe9467-0dc4-4879-c75a-edc74db3e40d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://visionai-artifacts/visionai-0.0.6-py3-none-any.whl...\n",
            "/ [1 files][377.8 KiB/377.8 KiB]                                                \n",
            "Operation completed over 1 objects/377.8 KiB.                                    \n",
            "Processing ./visionai-0.0.6-py3-none-any.whl\n",
            "Collecting absl-py>=1.4.0 (from visionai==0.0.6)\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting gcloud>=0.18.3 (from visionai==0.0.6)\n",
            "  Downloading gcloud-0.18.3.tar.gz (454 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.4/454.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting google-api-core>=2.10.2 (from visionai==0.0.6)\n",
            "  Downloading google_api_core-2.22.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting google-api-python-client>=2.85.0 (from visionai==0.0.6)\n",
            "  Downloading google_api_python_client-2.149.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting google-auth>=2.17.3 (from visionai==0.0.6)\n",
            "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting google-cloud-videointelligence>=2.11.1 (from visionai==0.0.6)\n",
            "  Downloading google_cloud_videointelligence-2.14.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting grpc-google-iam-v1>=0.12.4 (from visionai==0.0.6)\n",
            "  Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting grpcio>=1.53.0 (from visionai==0.0.6)\n",
            "  Downloading grpcio-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting proto-plus>=1.22.2 (from visionai==0.0.6)\n",
            "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting protobuf>=4.22.3 (from visionai==0.0.6)\n",
            "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting ratelimit>=2.2.1 (from visionai==0.0.6)\n",
            "  Downloading ratelimit-2.2.1.tar.gz (5.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests>=2.28.2 (from visionai==0.0.6)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting wheel>=0.34.2 (from visionai==0.0.6)\n",
            "  Downloading wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting httplib2>=0.9.1 (from gcloud>=0.18.3->visionai==0.0.6)\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting googleapis-common-protos (from gcloud>=0.18.3->visionai==0.0.6)\n",
            "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting oauth2client>=2.0.1 (from gcloud>=0.18.3->visionai==0.0.6)\n",
            "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting protobuf>=4.22.3 (from visionai==0.0.6)\n",
            "  Downloading protobuf-5.29.0rc2-cp38-abi3-manylinux2014_x86_64.whl.metadata (595 bytes)\n",
            "Collecting six (from gcloud>=0.18.3->visionai==0.0.6)\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client>=2.85.0->visionai==0.0.6)\n",
            "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client>=2.85.0->visionai==0.0.6)\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.17.3->visionai==0.0.6)\n",
            "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.17.3->visionai==0.0.6)\n",
            "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=2.17.3->visionai==0.0.6)\n",
            "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests>=2.28.2->visionai==0.0.6)\n",
            "  Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.28.2->visionai==0.0.6)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.28.2->visionai==0.0.6)\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.28.2->visionai==0.0.6)\n",
            "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-videointelligence>=2.11.1->visionai==0.0.6)\n",
            "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2>=0.9.1->gcloud>=0.18.3->visionai==0.0.6)\n",
            "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting pyasn1>=0.1.7 (from oauth2client>=2.0.1->gcloud>=0.18.3->visionai==0.0.6)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_core-2.22.0-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_python_client-2.149.0-py2.py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_videointelligence-2.14.0-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.2/254.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl (24 kB)\n",
            "Downloading grpcio-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.0rc2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.44.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
            "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_status-1.67.0-py3-none-any.whl (14 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gcloud, ratelimit\n",
            "  Building wheel for gcloud (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcloud: filename=gcloud-0.18.3-py3-none-any.whl size=602925 sha256=ff5504238d8911904d4a026e944c9bb7990276e9d50a6a270a11cfa376456a74\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/30/88/5017af921da3a33af785f0d0fd3e944b845bc62a445a2c2f69\n",
            "  Building wheel for ratelimit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ratelimit: filename=ratelimit-2.2.1-py3-none-any.whl size=5895 sha256=12a32e64a383728573b525a0765c4a29e4f8019792abef01b451227628971c96\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/5f/ba/e972a56dcbf5de9f2b7d2b2a710113970bd173c4dcd3d2c902\n",
            "Successfully built gcloud ratelimit\n",
            "Installing collected packages: ratelimit, wheel, urllib3, uritemplate, six, pyparsing, pyasn1, protobuf, idna, grpcio, charset-normalizer, certifi, cachetools, absl-py, rsa, requests, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, oauth2client, grpcio-status, google-auth, grpc-google-iam-v1, google-auth-httplib2, google-api-core, gcloud, google-api-python-client, google-cloud-videointelligence, visionai\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.44.0\n",
            "    Uninstalling wheel-0.44.0:\n",
            "      Successfully uninstalled wheel-0.44.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "  Attempting uninstall: uritemplate\n",
            "    Found existing installation: uritemplate 4.1.1\n",
            "    Uninstalling uritemplate-4.1.1:\n",
            "      Successfully uninstalled uritemplate-4.1.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.0\n",
            "    Uninstalling pyparsing-3.2.0:\n",
            "      Successfully uninstalled pyparsing-3.2.0\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.6.1\n",
            "    Uninstalling pyasn1-0.6.1:\n",
            "      Successfully uninstalled pyasn1-0.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.64.1\n",
            "    Uninstalling grpcio-1.64.1:\n",
            "      Successfully uninstalled grpcio-1.64.1\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.0\n",
            "    Uninstalling charset-normalizer-3.4.0:\n",
            "      Successfully uninstalled charset-normalizer-3.4.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.8.30\n",
            "    Uninstalling certifi-2024.8.30:\n",
            "      Successfully uninstalled certifi-2024.8.30\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.0\n",
            "    Uninstalling cachetools-5.5.0:\n",
            "      Successfully uninstalled cachetools-5.5.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1_modules 0.4.1\n",
            "    Uninstalling pyasn1_modules-0.4.1:\n",
            "      Successfully uninstalled pyasn1_modules-0.4.1\n",
            "  Attempting uninstall: proto-plus\n",
            "    Found existing installation: proto-plus 1.25.0\n",
            "    Uninstalling proto-plus-1.25.0:\n",
            "      Successfully uninstalled proto-plus-1.25.0\n",
            "  Attempting uninstall: httplib2\n",
            "    Found existing installation: httplib2 0.22.0\n",
            "    Uninstalling httplib2-0.22.0:\n",
            "      Successfully uninstalled httplib2-0.22.0\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.65.0\n",
            "    Uninstalling googleapis-common-protos-1.65.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.65.0\n",
            "  Attempting uninstall: oauth2client\n",
            "    Found existing installation: oauth2client 4.1.3\n",
            "    Uninstalling oauth2client-4.1.3:\n",
            "      Successfully uninstalled oauth2client-4.1.3\n",
            "  Attempting uninstall: grpcio-status\n",
            "    Found existing installation: grpcio-status 1.48.2\n",
            "    Uninstalling grpcio-status-1.48.2:\n",
            "      Successfully uninstalled grpcio-status-1.48.2\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.27.0\n",
            "    Uninstalling google-auth-2.27.0:\n",
            "      Successfully uninstalled google-auth-2.27.0\n",
            "  Attempting uninstall: grpc-google-iam-v1\n",
            "    Found existing installation: grpc-google-iam-v1 0.13.1\n",
            "    Uninstalling grpc-google-iam-v1-0.13.1:\n",
            "      Successfully uninstalled grpc-google-iam-v1-0.13.1\n",
            "  Attempting uninstall: google-auth-httplib2\n",
            "    Found existing installation: google-auth-httplib2 0.2.0\n",
            "    Uninstalling google-auth-httplib2-0.2.0:\n",
            "      Successfully uninstalled google-auth-httplib2-0.2.0\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.19.2\n",
            "    Uninstalling google-api-core-2.19.2:\n",
            "      Successfully uninstalled google-api-core-2.19.2\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.137.0\n",
            "    Uninstalling google-api-python-client-2.137.0:\n",
            "      Successfully uninstalled google-api-python-client-2.137.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.0rc2 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.0rc2 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth==2.27.0, but you have google-auth 2.35.0 which is incompatible.\n",
            "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.29.0rc2 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.0rc2 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.29.0rc2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-2.1.0 cachetools-5.5.0 certifi-2024.8.30 charset-normalizer-3.4.0 gcloud-0.18.3 google-api-core-2.22.0 google-api-python-client-2.149.0 google-auth-2.35.0 google-auth-httplib2-0.2.0 google-cloud-videointelligence-2.14.0 googleapis-common-protos-1.65.0 grpc-google-iam-v1-0.13.1 grpcio-1.67.0 grpcio-status-1.67.0 httplib2-0.22.0 idna-3.10 oauth2client-4.1.3 proto-plus-1.25.0 protobuf-5.29.0rc2 pyasn1-0.6.1 pyasn1-modules-0.4.1 pyparsing-3.2.0 ratelimit-2.2.1 requests-2.32.3 rsa-4.9 six-1.16.0 uritemplate-4.1.1 urllib3-2.2.3 visionai-0.0.6 wheel-0.44.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "google",
                  "httplib2",
                  "six"
                ]
              },
              "id": "1c13e7d1c5db4df0a38354aa2262107c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!gsutil cp gs://visionai-artifacts/visionai-0.0.6-py3-none-any.whl .\n",
        "!pip install visionai-0.0.6-py3-none-any.whl --force-reinstall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58707a750154"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f200f10a1da3"
      },
      "outputs": [],
      "source": [
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeRSrNTGZVBJ"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3i7BDALZqeQ"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOkFz5v6Z5mL",
        "outputId": "11dab1c8-81b7-432d-88e4-840d4eb074a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ID = \"bagchi-genai-bb\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ccc9e52986"
      },
      "source": [
        "**1. Vertex AI Workbench**\n",
        "* Do nothing as you are already authenticated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de775a3773ba"
      },
      "source": [
        "**2. Local JupyterLab instance, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "254614fa0c46"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef21552ccea8"
      },
      "source": [
        "**3. Colab, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "603adbbf0532"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixfp-_Ne09EK"
      },
      "source": [
        "### Set Up Other Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6ePddpJiGIb"
      },
      "outputs": [],
      "source": [
        "PROJECT_NUMBER_STR = !gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\n",
        "PROJECT_NUMBER = int(PROJECT_NUMBER_STR[0])\n",
        "\n",
        "# Only us-central1 is supported.\n",
        "REGION = \"us-central1\"\n",
        "\n",
        "CORPUS_DISPLAY_NAME = \"iwh demo corpus\"  # @param {type: \"string\"}\n",
        "CORPUS_DESCRIPTION = \"iwh demo corpus\"  # @param {type: \"string\"}\n",
        "\n",
        "# External users can only access PROD environment.\n",
        "ENV = \"PROD\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxXIz2fhpbe3"
      },
      "source": [
        "### Enable API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shwQ0FmCBzim"
      },
      "outputs": [],
      "source": [
        "!gcloud services enable \"visionai.googleapis.com\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_cXC20TXi7w"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWmMlMTXHyCt"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "import ipywidgets\n",
        "import requests\n",
        "from IPython.display import display\n",
        "from ipywidgets import GridspecLayout\n",
        "from visionai.python.gapic.visionai import visionai_v1\n",
        "from visionai.python.net import channel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oNEft7H-LFW"
      },
      "source": [
        "## Create a Warehouse client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17R9weLH-PSo"
      },
      "outputs": [],
      "source": [
        "warehouse_endpoint = channel.get_warehouse_service_endpoint(channel.Environment[ENV])\n",
        "warehouse_client = visionai_v1.WarehouseClient(\n",
        "    client_options={\"api_endpoint\": warehouse_endpoint}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P54JllW1VRZQ"
      },
      "source": [
        "## Create a Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRFymrurNUAp",
        "outputId": "d48f4f81-0f6a-414d-9bb3-6b0ad87612ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wait for corpus operation: name: \"projects/104454103637/locations/us-central1/warehouseOperations/CRC3266372182766938880\"\n",
            "metadata {\n",
            "  type_url: \"type.googleapis.com/google.cloud.visionai.v1.CreateCorpusMetadata\"\n",
            "  value: \"\\022\\014\\010\\230\\332\\377\\270\\006\\020\\250\\354\\333\\222\\001\\032\\014\\010\\230\\332\\377\\270\\006\\020\\330\\252\\245\\357\\001\"\n",
            "}\n",
            "\n",
            "Created corpus  name: \"projects/104454103637/locations/us-central1/corpora/4862123093363351097\"\n",
            "display_name: \"iwh demo corpus\"\n",
            "description: \"iwh demo corpus\"\n",
            "type_: IMAGE\n",
            "search_capability_setting {\n",
            "  search_capabilities {\n",
            "    type_: EMBEDDING_SEARCH\n",
            "  }\n",
            "}\n",
            "\n",
            "Corpus created: projects/104454103637/locations/us-central1/corpora/4862123093363351097\n"
          ]
        }
      ],
      "source": [
        "# Set CORPUS_NAME to empty string to create new corpus\n",
        "CORPUS_NAME = \"\"  # @param {type: \"string\"}\n",
        "\n",
        "if CORPUS_NAME == \"\":\n",
        "    search_capability = visionai_v1.SearchCapability(\n",
        "        type_=visionai_v1.SearchCapability.Type.EMBEDDING_SEARCH\n",
        "    )\n",
        "    operation = warehouse_client.create_corpus(\n",
        "        visionai_v1.CreateCorpusRequest(\n",
        "            parent=f\"projects/{PROJECT_NUMBER}/locations/{REGION}\",\n",
        "            corpus=visionai_v1.Corpus(\n",
        "                display_name=CORPUS_DISPLAY_NAME,\n",
        "                description=CORPUS_DESCRIPTION,\n",
        "                type_=visionai_v1.Corpus.Type.IMAGE,\n",
        "                search_capability_setting=visionai_v1.SearchCapabilitySetting(\n",
        "                    search_capabilities=[search_capability]\n",
        "                ),\n",
        "            ),\n",
        "        )\n",
        "    )\n",
        "    print(\"Wait for corpus operation:\", operation.operation)\n",
        "\n",
        "    print(\"Created corpus \", operation.result(timeout=7200))\n",
        "    corpus_name = operation.result().name\n",
        "    print(\"Corpus created:\", corpus_name)\n",
        "else:\n",
        "    corpus_name = CORPUS_NAME\n",
        "    print(\"Corpus: \", corpus_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvtPdSmwVc9_"
      },
      "source": [
        "## Create DataSchema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrNSA_JXnzCj",
        "outputId": "1b2ceccc-f197-4253-a314-21a65eb2dcc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: \"projects/104454103637/locations/us-central1/corpora/4862123093363351097/dataSchemas/width\"\n",
            "key: \"width\"\n",
            "schema_details {\n",
            "  type_: STRING\n",
            "  granularity: GRANULARITY_ASSET_LEVEL\n",
            "  search_strategy {\n",
            "    search_strategy_type: EXACT_SEARCH\n",
            "  }\n",
            "}\n",
            "\n",
            "name: \"projects/104454103637/locations/us-central1/corpora/4862123093363351097/dataSchemas/height\"\n",
            "key: \"height\"\n",
            "schema_details {\n",
            "  type_: STRING\n",
            "  granularity: GRANULARITY_ASSET_LEVEL\n",
            "  search_strategy {\n",
            "    search_strategy_type: EXACT_SEARCH\n",
            "  }\n",
            "}\n",
            "\n",
            "name: \"projects/104454103637/locations/us-central1/corpora/4862123093363351097/dataSchemas/aspect-ratio\"\n",
            "key: \"aspect-ratio\"\n",
            "schema_details {\n",
            "  type_: STRING\n",
            "  granularity: GRANULARITY_ASSET_LEVEL\n",
            "  search_strategy {\n",
            "    search_strategy_type: EXACT_SEARCH\n",
            "  }\n",
            "}\n",
            "\n",
            "name: \"projects/104454103637/locations/us-central1/corpora/4862123093363351097/dataSchemas/creator\"\n",
            "key: \"creator\"\n",
            "schema_details {\n",
            "  type_: STRING\n",
            "  granularity: GRANULARITY_ASSET_LEVEL\n",
            "  search_strategy {\n",
            "    search_strategy_type: EXACT_SEARCH\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Set SCHEMA_NAME_* to empty strings to create new schemas.\n",
        "SCHEMA_NAME_WIDTH = \"\"  # @param {type: \"string\"}\n",
        "SCHEMA_NAME_HEIGHT = \"\"  # @param {type: \"string\"}\n",
        "SCHEMA_NAME_ASPECT = \"\"  # @param {type: \"string\"}\n",
        "SCHEMA_NAME_CREATOR = \"\"  # @param {type: \"string\"}\n",
        "\n",
        "if SCHEMA_NAME_WIDTH == \"\":\n",
        "    schema_width = warehouse_client.create_data_schema(\n",
        "        visionai_v1.CreateDataSchemaRequest(\n",
        "            parent=corpus_name,\n",
        "            data_schema=visionai_v1.DataSchema(\n",
        "                key=\"width\",\n",
        "                schema_details=visionai_v1.DataSchemaDetails(\n",
        "                    type_=visionai_v1.DataSchemaDetails.DataType.STRING,\n",
        "                    granularity=visionai_v1.DataSchemaDetails.Granularity.GRANULARITY_ASSET_LEVEL,\n",
        "                    search_strategy=visionai_v1.DataSchemaDetails.SearchStrategy(\n",
        "                        search_strategy_type=visionai_v1.DataSchemaDetails.SearchStrategy.SearchStrategyType.EXACT_SEARCH\n",
        "                    ),\n",
        "                ),\n",
        "            ),\n",
        "        )\n",
        "    )\n",
        "    print(schema_width)\n",
        "    schema_name_width = schema_width.name\n",
        "else:\n",
        "    schema_name_width = SCHEMA_NAME_WIDTH\n",
        "\n",
        "if SCHEMA_NAME_HEIGHT == \"\":\n",
        "    schema_height = warehouse_client.create_data_schema(\n",
        "        visionai_v1.CreateDataSchemaRequest(\n",
        "            parent=corpus_name,\n",
        "            data_schema=visionai_v1.DataSchema(\n",
        "                key=\"height\",\n",
        "                schema_details=visionai_v1.DataSchemaDetails(\n",
        "                    type_=visionai_v1.DataSchemaDetails.DataType.STRING,\n",
        "                    granularity=visionai_v1.DataSchemaDetails.Granularity.GRANULARITY_ASSET_LEVEL,\n",
        "                    search_strategy=visionai_v1.DataSchemaDetails.SearchStrategy(\n",
        "                        search_strategy_type=visionai_v1.DataSchemaDetails.SearchStrategy.SearchStrategyType.EXACT_SEARCH\n",
        "                    ),\n",
        "                ),\n",
        "            ),\n",
        "        )\n",
        "    )\n",
        "    print(schema_height)\n",
        "    schema_name_height = schema_height.name\n",
        "else:\n",
        "    schema_name_height = SCHEMA_NAME_HEIGHT\n",
        "\n",
        "if SCHEMA_NAME_ASPECT == \"\":\n",
        "    schema_aspect = warehouse_client.create_data_schema(\n",
        "        visionai_v1.CreateDataSchemaRequest(\n",
        "            parent=corpus_name,\n",
        "            data_schema=visionai_v1.DataSchema(\n",
        "                key=\"aspect-ratio\",\n",
        "                schema_details=visionai_v1.DataSchemaDetails(\n",
        "                    type_=visionai_v1.DataSchemaDetails.DataType.STRING,\n",
        "                    granularity=visionai_v1.DataSchemaDetails.Granularity.GRANULARITY_ASSET_LEVEL,\n",
        "                    search_strategy=visionai_v1.DataSchemaDetails.SearchStrategy(\n",
        "                        search_strategy_type=visionai_v1.DataSchemaDetails.SearchStrategy.SearchStrategyType.EXACT_SEARCH\n",
        "                    ),\n",
        "                ),\n",
        "            ),\n",
        "        )\n",
        "    )\n",
        "    print(schema_aspect)\n",
        "    schema_name_aspect = schema_aspect.name\n",
        "else:\n",
        "    schema_name_aspect = SCHEMA_NAME_ASPECT\n",
        "\n",
        "if SCHEMA_NAME_CREATOR == \"\":\n",
        "    schema_creator = warehouse_client.create_data_schema(\n",
        "        visionai_v1.CreateDataSchemaRequest(\n",
        "            parent=corpus_name,\n",
        "            data_schema=visionai_v1.DataSchema(\n",
        "                key=\"creator\",\n",
        "                schema_details=visionai_v1.DataSchemaDetails(\n",
        "                    type_=visionai_v1.DataSchemaDetails.DataType.STRING,\n",
        "                    granularity=visionai_v1.DataSchemaDetails.Granularity.GRANULARITY_ASSET_LEVEL,\n",
        "                    search_strategy=visionai_v1.DataSchemaDetails.SearchStrategy(\n",
        "                        search_strategy_type=visionai_v1.DataSchemaDetails.SearchStrategy.SearchStrategyType.EXACT_SEARCH\n",
        "                    ),\n",
        "                ),\n",
        "            ),\n",
        "        )\n",
        "    )\n",
        "    print(schema_creator)\n",
        "    schema_name_creator = schema_creator.name\n",
        "else:\n",
        "    schema_name_creator = SCHEMA_NAME_CREATOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt4Z_PPB2ulp"
      },
      "source": [
        "## Import Assets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSnwkgjirdZ-",
        "outputId": "b00d2121-f423-45cf-b531-1e4014c85c5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wait for import operation:  name: \"projects/104454103637/locations/us-central1/corpora/4862123093363351097/operations/IMA5234429413078751845\"\n",
            "metadata {\n",
            "  type_url: \"type.googleapis.com/google.cloud.visionai.v1.ImportAssetsMetadata\"\n",
            "  value: \"\\n\\r\\n\\013\\010\\314\\332\\377\\270\\006\\020\\240\\200\\2303\"\n",
            "}\n",
            "\n",
            "Import operation done:  name: \"projects/104454103637/locations/us-central1/corpora/4862123093363351097/operations/IMA5234429413078751845\"\n",
            "metadata {\n",
            "  type_url: \"type.googleapis.com/google.cloud.visionai.v1.ImportAssetsMetadata\"\n",
            "  value: \"\\n\\032\\n\\013\\010\\314\\332\\377\\270\\006\\020\\240\\200\\2303\\022\\013\\010\\351\\346\\377\\270\\006\\020\\270\\324\\266\\003\\022\\003\\010\\326\\034\"\n",
            "}\n",
            "done: true\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Upload images into a gcs bucket and prepare the input gcs file.\n",
        "\n",
        "# Set IMPORT_ASSET to True to import assets.\n",
        "IMPORT_ASSET = True  # @param {type: \"boolean\"}\n",
        "INPUT_GCS_FILE = \"gs://cloud-samples-data/vertex-ai-vision/warehouse/demo.jsonl\"  # @param {type: \"string\"}\n",
        "\n",
        "if IMPORT_ASSET:\n",
        "    import_lro = warehouse_client.import_assets(\n",
        "        visionai_v1.ImportAssetsRequest(\n",
        "            parent=f\"{corpus_name}\",\n",
        "            assets_gcs_uri=f\"{INPUT_GCS_FILE}\",\n",
        "        )\n",
        "    )\n",
        "    print(\"Wait for import operation: \", import_lro.operation)\n",
        "    while not import_lro.done():\n",
        "        time.sleep(10)\n",
        "    print(\"Import operation done: \", import_lro.operation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9F9KejLVnNA"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "##  Analyze Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya64vk-7xybh",
        "outputId": "6d204310-3467-4383-c50f-db9f5f96c992",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wait for analyze operation:  name: \"projects/104454103637/locations/us-central1/corpora/4862123093363351097/operations/ALC7543216244904925481\"\n",
            "metadata {\n",
            "  type_url: \"type.googleapis.com/google.cloud.visionai.v1.AnalyzeCorpusMetadata\"\n",
            "  value: \"\\n\\016\\n\\014\\010\\373\\353\\377\\270\\006\\020\\340\\324\\217\\366\\001\"\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Set ANALYZE_CORPUS to True to analyze all assets in the corpus\n",
        "ANALYZE_CORPUS = True  # @param {type: \"boolean\"}\n",
        "\n",
        "if ANALYZE_CORPUS:\n",
        "    analyze_lro = warehouse_client.analyze_corpus(\n",
        "        visionai_v1.AnalyzeCorpusRequest(\n",
        "            name=f\"{corpus_name}\",\n",
        "        )\n",
        "    )\n",
        "    print(\"Wait for analyze operation: \", analyze_lro.operation)\n",
        "    while not analyze_lro.done():\n",
        "        time.sleep(10)\n",
        "    print(\"Analyze operation done: \", analyze_lro.operation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9ZNCVXQ5xqL"
      },
      "source": [
        "## Create and deploy Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCDTWM1fV4FQ"
      },
      "source": [
        "### Create Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqjwPISF2lEp"
      },
      "outputs": [],
      "source": [
        "# Set INDEX_NAME to empty string to create a new index\n",
        "INDEX_NAME = \"\"  # @param {type: \"string\"}\n",
        "\n",
        "if INDEX_NAME == \"\":\n",
        "    IMAGE_INDEX_ID = \"image-index-demo\"\n",
        "    index_lro = warehouse_client.create_index(\n",
        "        visionai_v1.CreateIndexRequest(\n",
        "            parent=corpus_name,\n",
        "            index_id=f\"{IMAGE_INDEX_ID}\",\n",
        "            index=visionai_v1.Index(\n",
        "                entire_corpus=True,\n",
        "                display_name=\"demo index\",\n",
        "                description=\"demo index\",\n",
        "            ),\n",
        "        )\n",
        "    )\n",
        "    print(\"Wait for index operation:\", index_lro.operation)\n",
        "\n",
        "    print(\"Created index \", index_lro.result(timeout=10800))\n",
        "    index_name = index_lro.result().name\n",
        "    print(\"Index created:\", index_name)\n",
        "else:\n",
        "    index_name = INDEX_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUq7XtDqV99n"
      },
      "source": [
        "### Create Index Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jT7OloPI-sGg"
      },
      "outputs": [],
      "source": [
        "# Set INDEX_NAME to empty string to create a new index\n",
        "ENDPOINT_NAME = \"\"  # @param {type: \"string\"}\n",
        "\n",
        "if ENDPOINT_NAME == \"\":\n",
        "    ENDPOINT_ID = \"search-endpoint-demo\"\n",
        "    endpoint_lro = warehouse_client.create_index_endpoint(\n",
        "        visionai_v1.CreateIndexEndpointRequest(\n",
        "            parent=f\"projects/{PROJECT_NUMBER}/locations/{REGION}\",\n",
        "            index_endpoint_id=f\"{ENDPOINT_ID}\",\n",
        "            index_endpoint=visionai_v1.IndexEndpoint(\n",
        "                display_name=\"demo index endpoint\",\n",
        "                description=\"demo index endpoint\",\n",
        "            ),\n",
        "        )\n",
        "    )\n",
        "    print(\"Wait for endpoint operation:\", endpoint_lro.operation)\n",
        "\n",
        "    print(\"Created endpoint \", endpoint_lro.result(timeout=7200))\n",
        "    endpoint_name = endpoint_lro.result().name\n",
        "    print(\"Endpoint created:\", endpoint_name)\n",
        "else:\n",
        "    endpoint_name = ENDPOINT_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PUBzMdGWC3_"
      },
      "source": [
        "### Deploy Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdYVtCDgBFmA"
      },
      "outputs": [],
      "source": [
        "# Set DEPLOY_INDEX to True to deploy the index to the endpoint\n",
        "DEPLOY_INDEX = True  # @param {type: \"boolean\"}\n",
        "\n",
        "if DEPLOY_INDEX:\n",
        "    deploy_lro = warehouse_client.deploy_index(\n",
        "        visionai_v1.DeployIndexRequest(\n",
        "            index_endpoint=endpoint_name,\n",
        "            deployed_index=visionai_v1.DeployedIndex(\n",
        "                index=index_name,\n",
        "            ),\n",
        "        )\n",
        "    )\n",
        "    print(\"Wait for deploy operation:\", deploy_lro.operation)\n",
        "\n",
        "    print(deploy_lro.result(timeout=7200))\n",
        "    print(\"Deployed Index: \", deploy_lro.operation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRrvMMeLQ7lz"
      },
      "source": [
        "## Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l6nQbZ--X_B"
      },
      "source": [
        "### Util for rending images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WTqnBAP-a78"
      },
      "outputs": [],
      "source": [
        "def RenderImages(cols=5, image_uris=[]):\n",
        "    assert len(image_uris) > 0\n",
        "    assert cols > 0\n",
        "    rows = math.floor((len(image_uris) - 1) / cols) + 1\n",
        "    grid = GridspecLayout(rows, cols)\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            index = i * cols + j\n",
        "            if index >= len(image_uris):\n",
        "                break\n",
        "            grid[i, j] = ipywidgets.Image(\n",
        "                value=requests.get(image_uris[index]).content, width=200\n",
        "            )\n",
        "    display(grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSTndOjsWNb_"
      },
      "source": [
        "### Search by text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caBg19gEQ96i"
      },
      "outputs": [],
      "source": [
        "MAX_RESULTS = 10  # @param {type: \"integer\"} Set to 0 to allow all results.\n",
        "QUERY = \"multiple purple tulips\"  # @param {type: \"string\"}\n",
        "\n",
        "results = warehouse_client.search_index_endpoint(\n",
        "    visionai_v1.SearchIndexEndpointRequest(\n",
        "        index_endpoint=endpoint_name,\n",
        "        text_query=QUERY,\n",
        "    ),\n",
        ")\n",
        "\n",
        "results_cnt = 0\n",
        "asset_names = []\n",
        "for r in results:\n",
        "    asset_names.append(r.asset)\n",
        "    results_cnt += 1\n",
        "    if results_cnt >= MAX_RESULTS:\n",
        "        break\n",
        "\n",
        "uris = list(\n",
        "    map(\n",
        "        lambda asset_name: warehouse_client.generate_retrieval_url(\n",
        "            visionai_v1.GenerateRetrievalUrlRequest(\n",
        "                name=asset_name,\n",
        "            )\n",
        "        ).signed_uri,\n",
        "        asset_names,\n",
        "    )\n",
        ")\n",
        "\n",
        "RenderImages(image_uris=uris)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T_UnnT6WQAH"
      },
      "source": [
        "### Search by image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4wDqMEFDK8G"
      },
      "outputs": [],
      "source": [
        "IMAGE_GCS_FILE = \"gs://cloud-samples-data/ai-platform/flowers/roses/14312910041_b747240d56_n.jpg\"  # @#param {type: \"string\"} example: gs://iwh_fishfood/sample-image.jpg\n",
        "MAX_RESULTS = 10  # @#param {type: \"integer\"} Set to 0 to allow all results.\n",
        "IMAGE_FILE = \"/tmp/sample-image.jpg\"\n",
        "!gsutil cp $IMAGE_GCS_FILE $IMAGE_FILE\n",
        "\n",
        "with open(IMAGE_FILE, \"rb\") as f:\n",
        "    image_content = f.read()\n",
        "grid = GridspecLayout(1, 1)\n",
        "grid[0, 0] = ipywidgets.Image(value=image_content, width=200)\n",
        "\n",
        "print(\"Query image:\")\n",
        "display(grid)\n",
        "\n",
        "results = warehouse_client.search_index_endpoint(\n",
        "    visionai_v1.SearchIndexEndpointRequest(\n",
        "        index_endpoint=endpoint_name,\n",
        "        image_query=visionai_v1.ImageQuery(\n",
        "            input_image=image_content,\n",
        "        ),\n",
        "    ),\n",
        ")\n",
        "\n",
        "results_cnt = 0\n",
        "asset_names = []\n",
        "for r in results:\n",
        "    asset_names.append(r.asset)\n",
        "    results_cnt += 1\n",
        "    if results_cnt >= MAX_RESULTS:\n",
        "        break\n",
        "\n",
        "uris = list(\n",
        "    map(\n",
        "        lambda asset_name: warehouse_client.generate_retrieval_url(\n",
        "            visionai_v1.GenerateRetrievalUrlRequest(\n",
        "                name=asset_name,\n",
        "            )\n",
        "        ).signed_uri,\n",
        "        asset_names,\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"Search results:\")\n",
        "RenderImages(image_uris=uris)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzkQSEOMbB5B"
      },
      "source": [
        "## Cleaning up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IpVtfcywIl9"
      },
      "outputs": [],
      "source": [
        "CLEAN_UP = False  # @param {type: \"boolean\"}\n",
        "if CLEAN_UP:\n",
        "    undeploy_lro = warehouse_client.undeploy_index(\n",
        "        visionai_v1.UndeployIndexRequest(\n",
        "            index_endpoint=endpoint_name,\n",
        "        )\n",
        "    )\n",
        "    print(\"Wait for undeploy operation:\", undeploy_lro.operation)\n",
        "\n",
        "    print(undeploy_lro.result(timeout=7200))\n",
        "\n",
        "    delete_index_lro = warehouse_client.delete_index(\n",
        "        visionai_v1.DeleteIndexRequest(\n",
        "            name=index_name,\n",
        "        )\n",
        "    )\n",
        "    print(\"Wait for delete operation:\", delete_index_lro.operation)\n",
        "\n",
        "    delete_endpoint_lro = warehouse_client.delete_index_endpoint(\n",
        "        visionai_v1.DeleteIndexEndpointRequest(\n",
        "            name=endpoint_name,\n",
        "        )\n",
        "    )\n",
        "    print(\"Wait for delete operation:\", delete_endpoint_lro.operation)\n",
        "\n",
        "    while True:\n",
        "        assets = warehouse_client.list_assets(\n",
        "            visionai_v1.ListAssetsRequest(\n",
        "                parent=corpus_name,\n",
        "                page_size=1000,\n",
        "            )\n",
        "        )\n",
        "        deletion_cnt = 0\n",
        "        for a in assets:\n",
        "            deletion_cnt += 1\n",
        "            print(\"Deleting asset:\", a.name)\n",
        "            warehouse_client.delete_asset(\n",
        "                visionai_v1.DeleteAssetRequest(\n",
        "                    name=a.name,\n",
        "                )\n",
        "            )\n",
        "            if deletion_cnt == 1000:\n",
        "                break\n",
        "        if deletion_cnt < 1000:\n",
        "            break\n",
        "\n",
        "    warehouse_client.delete_corpus(\n",
        "        visionai_v1.DeleteCorpusRequest(\n",
        "            name=corpus_name,\n",
        "        )\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}